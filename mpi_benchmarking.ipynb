{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_dQFF6-ZrlK"
   },
   "source": [
    "# Benchmarking for MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx12JTYiZrlS"
   },
   "source": [
    "This notebook benchmarks code for the MPI data-parallel implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This code sets up the necessary libraries and downloads the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install mpi4py\n",
    "!pip install requests\n",
    "\n",
    "# Download the datasets necessary\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download Penn Treebank dataset\n",
    "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
    "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
    "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
    "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
    "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
    "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y0HsJbj_5N_"
   },
   "source": [
    "## Single core w/ Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train on a single node with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHfqDwRR9BPa",
    "outputId": "4a075e80-e78f-41e7-d79c-610b8cf99017"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import ResNet9\n",
    "from simple_ml import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.cpu_numpy()\n",
    "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ndl.data.DataLoader(\\\n",
    "         dataset=dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,)\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, dataloader, n_epochs=2, optimizer=ndl.optim.Adam,\n",
    "      lr=0.001, weight_decay=0.001, device=device)\n",
    "print(\"Evaluating on test dataset...\")\n",
    "test_dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=False)\n",
    "test_dataloader = ndl.data.DataLoader(\\\n",
    "         dataset=test_dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,)\n",
    "evaluate_cifar10(model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqkN9-IN_9S2"
   },
   "source": [
    "## Multicore w/ Numpy, with Data Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try training with 2, 4, and 8 ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiqk8MATunfh",
    "outputId": "f2f3eac4-c371-4006-935d-45669fe6a8df"
   },
   "outputs": [],
   "source": [
    "!mpirun --allow-run-as-root -np 2 python apps/simple_ml_mpi.py 2 64 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiVXpPmRb3iL",
    "outputId": "cf7f6f2a-f4c3-420c-f352-c0a888279fc5"
   },
   "outputs": [],
   "source": [
    "!mpirun --allow-run-as-root -np 4 python apps/simple_ml_mpi.py 5 32 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAMzpfH-b4OQ",
    "outputId": "e0d24b11-b6a4-4ceb-cfd7-0447cafdae63"
   },
   "outputs": [],
   "source": [
    "!mpirun --allow-run-as-root -np 8 python apps/simple_ml_mpi.py 5 16 numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGP37eGlZrlT"
   },
   "source": [
    "# Language Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK8X7t7AZrlT"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import LanguageModel\n",
    "from simple_ml import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ndl.msl()\n",
    "corpus = ndl.data.Corpus(\"data/ptb\")\n",
    "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
    "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=device)\n",
    "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
    "evaluate_ptb(model, train_data, seq_len=40, device=device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
