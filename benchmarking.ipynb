{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6536eb31",
   "metadata": {},
   "source": [
    "# Metal Backend for Needle\n",
    "\n",
    "Metal is Apple's graphics and compute API for Apple Silicon GPUs, similar\n",
    "to CUDA for NVIDIA GPUs. We have written a Metal backend for Needle using\n",
    "Metal Shading Language (MSL), analogous to the CUDA backend. We have also\n",
    "written a Metal backend using Metal Performance Shaders (MPS), a library of \n",
    "highly optimized GPU kernels for e.g. matrix multiplication. PyTorch's \n",
    "Metal backend is built on top of MPS.\n",
    "\n",
    "We benchmarked the following backends:\n",
    "\n",
    "- PyTorch CPU\n",
    "- PyTorch MPS\n",
    "- Needle CPU\n",
    "- Needle MSL\n",
    "- Needle MPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93392e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b17596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('./python')\n",
    "import needle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71573c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_torch_cpu = torch.device(\"cpu\")\n",
    "device_torch_mps = torch.device(\"mps\") if torch.backends.mps.is_available() else None\n",
    "device_needle_cpu = needle.cpu()\n",
    "device_needle_msl = needle.msl()\n",
    "device_needle_mps = needle.mps()\n",
    "\n",
    "def torch_mps_synchronize():\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.synchronize()\n",
    "\n",
    "def needle_msl_synchronize():\n",
    "    needle.backend_ndarray.ndarray_backend_msl.synchronize()\n",
    "\n",
    "def needle_mps_synchronize():\n",
    "    needle.backend_ndarray.ndarray_backend_mps.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38850e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_fn(fn, warmup=5, iters=20, sync_fn=None):\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "        if sync_fn is not None:\n",
    "            sync_fn()\n",
    "    # timed\n",
    "    times = []\n",
    "    for _ in range(iters):\n",
    "        if sync_fn is not None:\n",
    "            sync_fn()   # optional: ensure previous work is done\n",
    "        t0 = time.perf_counter()\n",
    "        fn()\n",
    "        if sync_fn is not None:\n",
    "            sync_fn()\n",
    "        t1 = time.perf_counter()\n",
    "        times.append((t1 - t0) * 1e3)  # ms\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed color palette per backend for plotting\n",
    "COLOR_MAP = {\n",
    "    (\"pytorch\", \"cpu\"): \"#1f77b4\",   # blue\n",
    "    (\"pytorch\", \"mps\"): \"#ff7f0e\",   # orange\n",
    "    (\"needle\",  \"cpu\"): \"#2ca02c\",   # green\n",
    "    (\"needle\",  \"msl\"): \"#d62728\",   # red\n",
    "    (\"needle\",  \"mps\"): \"#9467bd\",   # purple\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767fa89",
   "metadata": {},
   "source": [
    "## Matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634838c",
   "metadata": {},
   "source": [
    "### Matmul Benchmarking Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1feee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch CPU\n",
    "\n",
    "def make_matmul_inputs_torch_cpu(m, k, n):\n",
    "    A = torch.from_numpy(\n",
    "        rng.standard_normal((m, k), dtype=np.float32)\n",
    "    ).to(device_torch_cpu, dtype=torch.float32)\n",
    "    B = torch.from_numpy(\n",
    "        rng.standard_normal((k, n), dtype=np.float32)\n",
    "    ).to(device_torch_cpu, dtype=torch.float32)\n",
    "    return A, B\n",
    "\n",
    "def benchmark_torch_cpu_matmul(A, B):\n",
    "    def fn():\n",
    "        with torch.no_grad():\n",
    "            _ = A @ B\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# PyTorch MPS\n",
    "\n",
    "def make_matmul_inputs_torch_mps(m, k, n):\n",
    "    A = torch.from_numpy(\n",
    "        rng.standard_normal((m, k), dtype=np.float32)\n",
    "    ).to(device_torch_mps, dtype=torch.float32)\n",
    "    B = torch.from_numpy(\n",
    "        rng.standard_normal((k, n), dtype=np.float32)\n",
    "    ).to(device_torch_mps, dtype=torch.float32)\n",
    "    return A, B\n",
    "\n",
    "def benchmark_torch_mps_matmul(A, B):\n",
    "    def fn():\n",
    "        with torch.no_grad():\n",
    "            _ = A @ B\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=torch_mps_synchronize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needle CPU\n",
    "\n",
    "def make_matmul_inputs_needle_cpu(m, k, n):\n",
    "    A = needle.Tensor(\n",
    "        rng.standard_normal((m, k), dtype=np.float32),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    B = needle.Tensor(\n",
    "        rng.standard_normal((k, n), dtype=np.float32),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return A, B\n",
    "\n",
    "def benchmark_needle_cpu_matmul(A, B):\n",
    "    def fn():\n",
    "        _ = A @ B\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# Needle MSL\n",
    "\n",
    "def make_matmul_inputs_needle_msl(m, k, n):\n",
    "    A = needle.Tensor(\n",
    "        rng.standard_normal((m, k), dtype=np.float32),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    B = needle.Tensor(\n",
    "        rng.standard_normal((k, n), dtype=np.float32),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return A, B\n",
    "\n",
    "def benchmark_needle_msl_matmul(A, B):\n",
    "    def fn():\n",
    "        _ = A @ B\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_msl_synchronize)\n",
    "\n",
    "\n",
    "# Needle MPS\n",
    "\n",
    "def make_matmul_inputs_needle_mps(m, k, n):\n",
    "    A = needle.Tensor(\n",
    "        rng.standard_normal((m, k), dtype=np.float32),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    B = needle.Tensor(\n",
    "        rng.standard_normal((k, n), dtype=np.float32),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return A, B\n",
    "\n",
    "def benchmark_needle_mps_matmul(A, B):\n",
    "    def fn():\n",
    "        _ = A @ B\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_mps_synchronize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_matmul_benchmarks(shapes, run_needle_cpu=False):\n",
    "    results = []\n",
    "\n",
    "    for label, m, k, n in shapes:\n",
    "        print(f\"\\n=== Shape {label}: A=({m},{k}), B=({k},{n}) ===\")\n",
    "\n",
    "        # PyTorch CPU\n",
    "        A_torch_cpu, B_torch_cpu = make_matmul_inputs_torch_cpu(m, k, n)\n",
    "        assert str(A_torch_cpu.device) == 'cpu', A_torch_cpu.device\n",
    "        mean_ms, std_ms = benchmark_torch_cpu_matmul(A_torch_cpu, B_torch_cpu)\n",
    "        gflops = (2.0 * m * k * n) / (mean_ms / 1e3) / 1e9 \n",
    "        print(f\"  PyTorch CPU: {mean_ms:.3f} ± {std_ms:.3f} ms, {gflops:.2f} GFLOP/s\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"pytorch\",\n",
    "            device=\"cpu\",\n",
    "            m=m, k=k, n=n,\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "            gflops=gflops,\n",
    "        ))\n",
    "\n",
    "        # PyTorch MPS (if available)\n",
    "        if device_torch_mps is not None:\n",
    "            A_torch_mps, B_torch_mps = make_matmul_inputs_torch_mps(m, k, n)\n",
    "            assert str(A_torch_mps.device).split(':')[0] == 'mps', A_torch_mps.device\n",
    "            mean_ms, std_ms = benchmark_torch_mps_matmul(A_torch_mps, B_torch_mps)\n",
    "            gflops = (2.0 * m * k * n) / (mean_ms / 1e3) / 1e9\n",
    "            print(f\"  PyTorch MPS: {mean_ms:.3f} ± {std_ms:.3f} ms, {gflops:.2f} GFLOP/s\")\n",
    "            results.append(dict(\n",
    "                label=label,\n",
    "                framework=\"pytorch\",\n",
    "                device=\"mps\",\n",
    "                m=m, k=k, n=n,\n",
    "                mean_ms=mean_ms,\n",
    "                std_ms=std_ms,\n",
    "                gflops=gflops,\n",
    "            ))\n",
    "\n",
    "        # Needle CPU\n",
    "        if run_needle_cpu:\n",
    "            A_needle_cpu, B_needle_cpu = make_matmul_inputs_needle_cpu(m, k, n)\n",
    "            assert A_needle_cpu.device == device_needle_cpu, A_needle_cpu.device\n",
    "            mean_ms, std_ms = benchmark_needle_cpu_matmul(A_needle_cpu, B_needle_cpu)\n",
    "            gflops = (2.0 * m * k * n) / (mean_ms / 1e3) / 1e9\n",
    "            print(f\"  Needle CPU: {mean_ms:.3f} ± {std_ms:.3f} ms, {gflops:.2f} GFLOP/s\")\n",
    "            results.append(dict(\n",
    "                label=label,\n",
    "                framework=\"needle\",\n",
    "                device=\"cpu\",\n",
    "                m=m, k=k, n=n,\n",
    "                mean_ms=mean_ms,\n",
    "                std_ms=std_ms,\n",
    "                gflops=gflops,\n",
    "            ))\n",
    "\n",
    "        # Needle MSL\n",
    "        A_needle_msl, B_needle_msl = make_matmul_inputs_needle_msl(m, k, n)\n",
    "        assert A_needle_msl.device == device_needle_msl, A_needle_msl.device\n",
    "        mean_ms, std_ms = benchmark_needle_msl_matmul(A_needle_msl, B_needle_msl)\n",
    "        gflops = (2.0 * m * k * n) / (mean_ms / 1e3) / 1e9\n",
    "        print(f\"  Needle MSL: {mean_ms:.3f} ± {std_ms:.3f} ms, {gflops:.2f} GFLOP/s\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"msl\",\n",
    "            m=m, k=k, n=n,\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "            gflops=gflops,\n",
    "        ))\n",
    "\n",
    "        # Needle MPS\n",
    "        A_needle_mps, B_needle_mps = make_matmul_inputs_needle_mps(m, k, n)\n",
    "        assert A_needle_mps.device == device_needle_mps, A_needle_mps.device\n",
    "        mean_ms, std_ms = benchmark_needle_mps_matmul(A_needle_mps, B_needle_mps)\n",
    "        gflops = (2.0 * m * k * n) / (mean_ms / 1e3) / 1e9\n",
    "        print(f\"  Needle MPS: {mean_ms:.3f} ± {std_ms:.3f} ms, {gflops:.2f} GFLOP/s\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"mps\",\n",
    "            m=m, k=k, n=n,\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "            gflops=gflops,\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matmul_gflops_grouped(df, only_needle=False):\n",
    "    labels = df[\"label\"].unique()\n",
    "    \n",
    "    # Unique backend combinations\n",
    "    groups = df[[\"framework\", \"device\"]].drop_duplicates()\n",
    "    groups = list(groups.itertuples(index=False, name=None)) \n",
    "    # e.g. [(\"pytorch\",\"cpu\"), (\"pytorch\",\"mps\"), (\"needle\",\"cpu\")]\n",
    "    if only_needle:\n",
    "        groups = [g for g in groups if g[0] == \"needle\"] \n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.8 / len(groups)   # auto-size bars nicely\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    for i, (framework, device) in enumerate(groups):\n",
    "        sub = df[(df[\"framework\"] == framework) & (df[\"device\"] == device)]\n",
    "        sub = sub.set_index(\"label\").loc[labels]\n",
    "\n",
    "        backend_label = f\"{framework.capitalize()} {device.upper()}\"\n",
    "        color = COLOR_MAP[(framework, device)]\n",
    "\n",
    "        plt.bar(\n",
    "            x + i * width,\n",
    "            sub[\"gflops\"],\n",
    "            width,\n",
    "            label=backend_label,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    plt.xticks(x + width * (len(groups)-1)/2, labels, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"GFLOP/s\")\n",
    "    plt.title(\"Matmul Performance by Backend\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94bca9f",
   "metadata": {},
   "source": [
    "### Run Matmul Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (label, m, k, n) for A: (m, k), B: (k, n)\n",
    "MATMUL_SHAPES = [\n",
    "    # Square-ish\n",
    "    (\"square_1024\",      1024, 1024, 1024),\n",
    "    (\"square_2048\",      2048, 2048, 2048),\n",
    "    (\"square_4096\",      4096, 4096, 4096),\n",
    "\n",
    "    # MLP-like (batch_size, in_dim, out_dim)\n",
    "    (\"mlp_64x1024x4096\",  64, 1024, 4096),\n",
    "    (\"mlp_256x1024x4096\", 256, 1024, 4096),\n",
    "    (\"mlp_64x4096x1024\",  64, 4096, 1024),\n",
    "    (\"mlp_64x2048x8192\",  64, 2048, 8192),\n",
    "    (\"mlp_32x512x2048\",   32,  512, 2048),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc06354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matmul = run_all_matmul_benchmarks(MATMUL_SHAPES, run_needle_cpu=True)\n",
    "df_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matmul_gflops_grouped(df_matmul, only_needle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf84da",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd708d1",
   "metadata": {},
   "source": [
    "### MLP Benchmarking Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60318290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear_weights(in_dim, out_dim):\n",
    "    w = rng.standard_normal((out_dim, in_dim), dtype=np.float32) * 0.02\n",
    "    b = np.zeros((out_dim,), dtype=np.float32)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch MLP\n",
    "class TorchMLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes, device=device_torch_cpu):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            linear = torch.nn.Linear(in_dim, out_dim, bias=True)\n",
    "\n",
    "            # Initialize weights using our function for consistency\n",
    "            w, b = init_linear_weights(in_dim, out_dim)\n",
    "            with torch.no_grad():\n",
    "                linear.weight.copy_(torch.from_numpy(w).to(device=device))\n",
    "                linear.bias.copy_(torch.from_numpy(b).to(device=device))\n",
    "            \n",
    "            layers.append(linear)\n",
    "            if i < len(layer_sizes) - 2:\n",
    "                layers.append(torch.nn.ReLU())\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "        # Optional: ensure any future buffers/params are on device too:\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Needle MLP\n",
    "class NeedleMLP(needle.nn.Module):\n",
    "    def __init__(self, layer_sizes, device=device_needle_cpu):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            linear = needle.nn.Linear(in_dim, out_dim, bias=True, device=device)\n",
    "\n",
    "            # Initialize weights using our function for consistency\n",
    "            w, b = init_linear_weights(in_dim, out_dim)\n",
    "            # Transpose to (in_dim, out_dim) for Needle\n",
    "            linear.weight = needle.nn.Parameter(\n",
    "                needle.Tensor(w.T, device=device, dtype=\"float32\")\n",
    "            )\n",
    "            # Reshape to (1, out_dim) for Needle\n",
    "            linear.bias = needle.nn.Parameter(\n",
    "                needle.Tensor(b.reshape(1, -1), device=device, dtype=\"float32\")\n",
    "            )\n",
    "\n",
    "            layers.append(linear)\n",
    "            if i < len(layer_sizes) - 2:\n",
    "                layers.append(needle.nn.ReLU())\n",
    "        self.net = needle.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch CPU \n",
    "\n",
    "def make_torch_cpu_model_and_data(layer_sizes, batch_size=64):\n",
    "    model = TorchMLP(layer_sizes, device=device_torch_cpu)\n",
    "    x = torch.from_numpy(\n",
    "        rng.standard_normal((batch_size, layer_sizes[0]), dtype=np.float32)\n",
    "    ).to(device_torch_cpu, dtype=torch.float32)\n",
    "    y = torch.from_numpy(\n",
    "        rng.integers(0, layer_sizes[-1], size=(batch_size,), dtype=np.int64)\n",
    "    ).to(device_torch_cpu, dtype=torch.int64)\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_torch_cpu_mlp_train_step(model, x, y, criterion, optimizer):\n",
    "    x = x.to(device_torch_cpu)\n",
    "    y = y.to(device_torch_cpu)\n",
    "\n",
    "    def fn():\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# PyTorch MPS\n",
    "\n",
    "def make_torch_mps_model_and_data(layer_sizes, batch_size=64):\n",
    "    model = TorchMLP(layer_sizes, device=device_torch_mps)\n",
    "    x = torch.from_numpy(\n",
    "        rng.standard_normal((batch_size, layer_sizes[0]), dtype=np.float32)\n",
    "    ).to(device_torch_mps, dtype=torch.float32)\n",
    "    y = torch.from_numpy(\n",
    "        rng.integers(0, layer_sizes[-1], size=(batch_size,), dtype=np.int64)\n",
    "    ).to(device_torch_mps, dtype=torch.int64)\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_torch_mps_mlp_train_step(model, x, y, criterion, optimizer):\n",
    "    x = x.to(device_torch_mps)\n",
    "    y = y.to(device_torch_mps)\n",
    "\n",
    "    def fn():\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=torch_mps_synchronize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needle CPU\n",
    "\n",
    "def make_needle_cpu_model_and_data(layer_sizes, batch_size=64):\n",
    "    model = NeedleMLP(layer_sizes, device=device_needle_cpu)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, layer_sizes[0]), dtype=np.float32),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, layer_sizes[-1], size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_cpu_mlp_train_step(model, x, y, criterion, optimizer):\n",
    "    assert x.device == device_needle_cpu, x.device\n",
    "    assert y.device == device_needle_cpu, y.device\n",
    "\n",
    "    def fn():\n",
    "        optimizer.reset_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# Needle MSL\n",
    "\n",
    "def make_needle_msl_model_and_data(layer_sizes, batch_size=64):\n",
    "    model = NeedleMLP(layer_sizes, device=device_needle_msl)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, layer_sizes[0]), dtype=np.float32),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, layer_sizes[-1], size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_msl_mlp_train_step(model, x, y, criterion, optimizer):\n",
    "    assert x.device == device_needle_msl, x.device\n",
    "    assert y.device == device_needle_msl, y.device\n",
    "\n",
    "    def fn():\n",
    "        optimizer.reset_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_msl_synchronize)\n",
    "\n",
    "\n",
    "# Needle MPS\n",
    "\n",
    "def make_needle_mps_model_and_data(layer_sizes, batch_size=64):\n",
    "    model = NeedleMLP(layer_sizes, device=device_needle_mps)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, layer_sizes[0]), dtype=np.float32),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, layer_sizes[-1], size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_mps_mlp_train_step(model, x, y, criterion, optimizer):\n",
    "    assert x.device == device_needle_mps, x.device\n",
    "    assert y.device == device_needle_mps, y.device\n",
    "\n",
    "    def fn():\n",
    "        optimizer.reset_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_mps_synchronize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e54093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_mlp_benchmarks(shapes):\n",
    "    results = []\n",
    "\n",
    "    for label, layer_sizes, batch_size in shapes:\n",
    "\n",
    "        print(f\"\\n=== MLP Shape {label}: layers={layer_sizes}, batch_size={batch_size} ===\")\n",
    "\n",
    "        # PyTorch CPU\n",
    "        model_torch_cpu, x_torch_cpu, y_torch_cpu = make_torch_cpu_model_and_data(\n",
    "            layer_sizes, batch_size\n",
    "        )\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model_torch_cpu.parameters(), lr=0.01)\n",
    "\n",
    "        mean_ms, std_ms = benchmark_torch_cpu_mlp_train_step(\n",
    "            model_torch_cpu, x_torch_cpu, y_torch_cpu, criterion, optimizer\n",
    "        )\n",
    "        print(f\"  PyTorch CPU: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"pytorch\",\n",
    "            device=\"cpu\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # PyTorch MPS\n",
    "        if device_torch_mps is not None:\n",
    "            model_torch_mps, x_torch_mps, y_torch_mps = make_torch_mps_model_and_data(\n",
    "                layer_sizes, batch_size\n",
    "            )\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.SGD(model_torch_mps.parameters(), lr=0.01)\n",
    "\n",
    "            mean_ms, std_ms = benchmark_torch_mps_mlp_train_step(\n",
    "                model_torch_mps, x_torch_mps, y_torch_mps, criterion, optimizer\n",
    "            )\n",
    "            print(f\"  PyTorch MPS: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "            results.append(dict(\n",
    "                label=label,\n",
    "                framework=\"pytorch\",\n",
    "                device=\"mps\",\n",
    "                mean_ms=mean_ms,\n",
    "                std_ms=std_ms,\n",
    "            ))\n",
    "        \n",
    "        # Needle CPU\n",
    "        model_needle_cpu, x_needle_cpu, y_needle_cpu = make_needle_cpu_model_and_data(\n",
    "            layer_sizes, batch_size\n",
    "        )\n",
    "        criterion = needle.nn.SoftmaxLoss()\n",
    "        optimizer = needle.optim.SGD(model_needle_cpu.parameters(), lr=0.01)\n",
    "\n",
    "        mean_ms, std_ms = benchmark_needle_cpu_mlp_train_step(\n",
    "            model_needle_cpu, x_needle_cpu, y_needle_cpu, criterion, optimizer\n",
    "        )\n",
    "        print(f\"  Needle CPU: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"cpu\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # Needle MSL\n",
    "        model_needle_msl, x_needle_msl, y_needle_msl = make_needle_msl_model_and_data(\n",
    "            layer_sizes, batch_size\n",
    "        )\n",
    "        criterion = needle.nn.SoftmaxLoss()\n",
    "        optimizer = needle.optim.SGD(model_needle_msl.parameters(), lr=0.01)\n",
    "\n",
    "        mean_ms, std_ms = benchmark_needle_msl_mlp_train_step(\n",
    "            model_needle_msl, x_needle_msl, y_needle_msl, criterion, optimizer\n",
    "        )\n",
    "        print(f\"  Needle MSL: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"msl\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # Needle MPS\n",
    "        model_needle_mps, x_needle_mps, y_needle_mps = make_needle_mps_model_and_data(\n",
    "            layer_sizes, batch_size\n",
    "        )\n",
    "        criterion = needle.nn.SoftmaxLoss()\n",
    "        optimizer = needle.optim.SGD(model_needle_mps.parameters(), lr=0.01)\n",
    "\n",
    "        mean_ms, std_ms = benchmark_needle_mps_mlp_train_step(\n",
    "            model_needle_mps, x_needle_mps, y_needle_mps, criterion, optimizer\n",
    "        )\n",
    "        print(f\"  Needle MPS: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"mps\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac074a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mlp_mean_ms_grouped(df, only_needle=False, show_needle_cpu=True):\n",
    "    labels = df[\"label\"].unique()\n",
    "    \n",
    "    groups = df[[\"framework\", \"device\"]].drop_duplicates()\n",
    "    groups = list(groups.itertuples(index=False, name=None))\n",
    "    if only_needle:\n",
    "        groups = [g for g in groups if g[0] == \"needle\"]\n",
    "    if not show_needle_cpu:\n",
    "        groups = [g for g in groups if not (g[0] == \"needle\" and g[1] == \"cpu\")]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.8 / max(1, len(groups))\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    for i, (framework, device) in enumerate(groups):\n",
    "        sub = df[(df[\"framework\"] == framework) & (df[\"device\"] == device)].set_index(\"label\")\n",
    "        sub = sub.loc[labels]  # keep original order\n",
    "        backend_label = f\"{framework.capitalize()} {device.upper()}\"\n",
    "        color = COLOR_MAP[(framework, device)]\n",
    "        plt.bar(x + i * width, sub[\"mean_ms\"], width, label=backend_label, color=color)\n",
    "\n",
    "    plt.xticks(x + width * (len(groups)-1)/2, labels, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Mean time per train step (ms)\")\n",
    "    plt.title(\"MLP Train-Step Performance by Backend\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af067a2b",
   "metadata": {},
   "source": [
    "### Run MLP Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (label, layer_sizes, batch_size) \n",
    "MLP_SHAPES = [\n",
    "    (\"tiny-2L-128\",         [128, 128, 10],                  64),\n",
    "    (\"med-4L-512\",          [512, 512, 512, 512, 10],        64),\n",
    "    (\"wide-2L-1024\",        [1024, 1024, 10],                64),\n",
    "    (\"deep-6L-1024\",        [1024]*6 + [10],                 64),\n",
    "    (\"maxwide-2L-2048\",     [2048, 2048, 10],                64),\n",
    "    (\"bneck-2048-64-2048\",  [2048, 64, 2048, 10],            64),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = run_all_mlp_benchmarks(MLP_SHAPES)\n",
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf080f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With CPU Needle\n",
    "plot_mlp_mean_ms_grouped(df_mlp, only_needle=False, show_needle_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without CPU Needle\n",
    "plot_mlp_mean_ms_grouped(df_mlp, only_needle=False, show_needle_cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75babe3a",
   "metadata": {},
   "source": [
    "## ResNet9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0257ff",
   "metadata": {},
   "source": [
    "### ResNet9 Benchmarking Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch ResNet9\n",
    "\n",
    "class TorchResidual(torch.nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "class TorchConvBN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 device=device_torch_cpu, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, \n",
    "            stride=stride, padding=padding, bias=True, device=device, dtype=dtype\n",
    "        )\n",
    "        self.bn = torch.nn.BatchNorm2d(out_channels, device=device, dtype=dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class TorchResNet9(torch.nn.Module):\n",
    "    def __init__(self, device=device_torch_cpu, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            TorchConvBN(3, 16, 7, stride=4, device=device, dtype=dtype),\n",
    "            TorchConvBN(16, 32, 3, stride=2, device=device, dtype=dtype),\n",
    "            TorchResidual(\n",
    "                torch.nn.Sequential(\n",
    "                    TorchConvBN(32, 32, 3, stride=1, device=device, dtype=dtype),\n",
    "                    TorchConvBN(32, 32, 3, stride=1, device=device, dtype=dtype),\n",
    "                )\n",
    "            ),\n",
    "            TorchConvBN(32, 64, 3, stride=2, device=device, dtype=dtype),\n",
    "            TorchConvBN(64, 128, 3, stride=2, device=device, dtype=dtype),\n",
    "            TorchResidual(\n",
    "                torch.nn.Sequential(\n",
    "                    TorchConvBN(128, 128, 3, stride=1, device=device, dtype=dtype),\n",
    "                    TorchConvBN(128, 128, 3, stride=1, device=device, dtype=dtype),\n",
    "                )\n",
    "            ),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, 128, device=device, dtype=dtype),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 10, device=device, dtype=dtype),\n",
    "        )\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# Needle ResNet9\n",
    "\n",
    "class NeedleConvBN(needle.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, \n",
    "                 device=device_needle_cpu, dtype=\"float32\"):\n",
    "        super().__init__()\n",
    "        self.conv = needle.nn.Conv(\n",
    "            in_channels, out_channels, kernel_size, \n",
    "            stride=stride, device=device, dtype=dtype, bias=True\n",
    "        )\n",
    "        self.bn = needle.nn.BatchNorm2d(out_channels, device=device, dtype=dtype)\n",
    "        self.relu = needle.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NeedleResNet9(needle.nn.Module):\n",
    "    def __init__(self, device=device_needle_cpu, dtype=\"float32\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = needle.nn.Sequential(\n",
    "            NeedleConvBN(3, 16, 7, stride=4, device=device, dtype=dtype),\n",
    "            NeedleConvBN(16, 32, 3, stride=2, device=device, dtype=dtype),\n",
    "            needle.nn.Residual(\n",
    "                needle.nn.Sequential(\n",
    "                    NeedleConvBN(32, 32, 3, stride=1, device=device, dtype=dtype),\n",
    "                    NeedleConvBN(32, 32, 3, stride=1, device=device, dtype=dtype),\n",
    "                )\n",
    "            ),\n",
    "            NeedleConvBN(32, 64, 3, stride=2, device=device, dtype=dtype),\n",
    "            NeedleConvBN(64, 128, 3, stride=2, device=device, dtype=dtype),\n",
    "            needle.nn.Residual(\n",
    "                needle.nn.Sequential(\n",
    "                    NeedleConvBN(128, 128, 3, stride=1, device=device, dtype=dtype),\n",
    "                    NeedleConvBN(128, 128, 3, stride=1, device=device, dtype=dtype),\n",
    "                )\n",
    "            ),\n",
    "            needle.nn.Flatten(),\n",
    "            needle.nn.Linear(512, 128, device=device, dtype=dtype),\n",
    "            needle.nn.ReLU(),\n",
    "            needle.nn.Linear(128, 10, device=device, dtype=dtype),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy init functions \n",
    "\n",
    "def init_conv(in_ch, out_ch, k, scale=0.02):\n",
    "    # w: (out_ch, in_ch, k, k)\n",
    "    # b: (out_ch,)\n",
    "    w = rng.standard_normal((out_ch, in_ch, k, k), dtype=np.float32) * scale\n",
    "    b = np.zeros((out_ch,), dtype=np.float32)\n",
    "    return w, b\n",
    "\n",
    "def init_linear(in_dim, out_dim, scale=0.02):\n",
    "    # w: (out_dim, in_dim)\n",
    "    # b: (out_dim,)\n",
    "    w = rng.standard_normal((out_dim, in_dim), dtype=np.float32) * scale\n",
    "    b = np.zeros((out_dim,), dtype=np.float32)\n",
    "    return w, b\n",
    "\n",
    "def init_bn(ch):\n",
    "    # gamma, beta, running_mean, running_var: (ch,)\n",
    "    gamma = np.ones((ch,), dtype=np.float32)\n",
    "    beta = np.zeros((ch,), dtype=np.float32)\n",
    "    running_mean = np.zeros((ch,), dtype=np.float32)\n",
    "    running_var = np.ones((ch,), dtype=np.float32)\n",
    "    return gamma, beta, running_mean, running_var\n",
    "\n",
    "\n",
    "# Load weights into PyTorch modules\n",
    "\n",
    "def load_torch_conv(module, w, b, device):\n",
    "    with torch.no_grad():\n",
    "        module.weight.copy_(torch.from_numpy(w).to(device=device))\n",
    "        module.bias.copy_(torch.from_numpy(b).to(device=device))\n",
    "   \n",
    "\n",
    "def load_torch_linear(module, w, b, device):\n",
    "    with torch.no_grad():\n",
    "        module.weight.copy_(torch.from_numpy(w).to(device=device))\n",
    "        module.bias.copy_(torch.from_numpy(b).to(device=device))\n",
    "\n",
    "def load_torch_bn(module, gamma, beta, running_mean, running_var, device):\n",
    "    with torch.no_grad():\n",
    "        module.weight.copy_(torch.from_numpy(gamma).to(device=device))\n",
    "        module.bias.copy_(torch.from_numpy(beta).to(device=device))\n",
    "        module.running_mean.copy_(torch.from_numpy(running_mean).to(device=device))\n",
    "        module.running_var.copy_(torch.from_numpy(running_var).to(device=device))\n",
    "\n",
    "\n",
    "# Load weights into Needle modules\n",
    "\n",
    "def load_needle_conv(module, w, b, device, dtype=\"float32\"):\n",
    "    # w is (out_ch, in_ch, k, k) -> transpose to (k, k, in_ch, out_ch)\n",
    "    w = np.transpose(w, (2, 3, 1, 0))\n",
    "    module.weight = needle.nn.Parameter(\n",
    "        needle.Tensor(w, device=device, dtype=dtype)\n",
    "    )\n",
    "    module.bias = needle.nn.Parameter(\n",
    "        needle.Tensor(b, device=device, dtype=dtype)\n",
    "    )\n",
    "\n",
    "def load_needle_linear(module, w, b, device, dtype=\"float32\"):\n",
    "    module.weight = needle.nn.Parameter(\n",
    "        needle.Tensor(w.T, device=device, dtype=dtype)\n",
    "    )\n",
    "    module.bias = needle.nn.Parameter(\n",
    "        needle.Tensor(b.reshape(1, -1), device=device, dtype=dtype)\n",
    "    )\n",
    "\n",
    "def load_needle_bn(module, gamma, beta, running_mean, running_var, device, dtype=\"float32\"):\n",
    "    module.weight = needle.nn.Parameter(\n",
    "        needle.Tensor(gamma, device=device, dtype=dtype)\n",
    "    )\n",
    "    module.bias = needle.nn.Parameter(\n",
    "        needle.Tensor(beta, device=device, dtype=dtype)\n",
    "    )\n",
    "    module.running_mean = needle.Tensor(\n",
    "        running_mean, device=device, dtype=dtype\n",
    "    )\n",
    "    module.running_var = needle.Tensor(\n",
    "        running_var, device=device, dtype=dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect matching layers from both models\n",
    "\n",
    "def get_torch_layers(model):\n",
    "    convs = []\n",
    "    linears = []\n",
    "    bns = []\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            convs.append(m)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            linears.append(m)\n",
    "        elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "            bns.append(m)\n",
    "    return convs, linears, bns\n",
    "\n",
    "def get_needle_layers(model):\n",
    "    convs = []\n",
    "    linears = []\n",
    "    bns = []\n",
    "    for m in model._children():\n",
    "        if isinstance(m, needle.nn.Conv):\n",
    "            convs.append(m)\n",
    "        elif isinstance(m, needle.nn.Linear):\n",
    "            linears.append(m)\n",
    "        elif isinstance(m, needle.nn.BatchNorm2d):\n",
    "            bns.append(m)\n",
    "    return convs, linears, bns\n",
    "\n",
    "\n",
    "# Sync weights\n",
    "\n",
    "def sync_torch_resnet9_weights(model, device, scale=0.02):\n",
    "    convs, linears, bns = get_torch_layers(model)\n",
    "\n",
    "    for conv in convs:\n",
    "        in_ch  = conv.in_channels\n",
    "        out_ch = conv.out_channels\n",
    "        k      = conv.kernel_size[0]  # assuming square kernels\n",
    "        w, b = init_conv(in_ch, out_ch, k, scale=scale)\n",
    "        load_torch_conv(conv, w, b, device=device)\n",
    "\n",
    "    for lin in linears:\n",
    "        in_dim  = lin.in_features\n",
    "        out_dim = lin.out_features\n",
    "        w, b = init_linear(in_dim, out_dim, scale=scale)\n",
    "        load_torch_linear(lin, w, b, device=device)\n",
    "\n",
    "    for bn in bns:\n",
    "        dim = bn.num_features\n",
    "        gamma, beta, running_mean, running_var = init_bn(dim)\n",
    "        load_torch_bn(bn, gamma, beta, running_mean, running_var, device=device)\n",
    "\n",
    "def sync_needle_resnet9_weights(model, device, dtype=\"float32\", scale=0.02):\n",
    "    convs, linears, bns = get_needle_layers(model)\n",
    "\n",
    "    for conv in convs:\n",
    "        in_ch  = conv.in_channels\n",
    "        out_ch = conv.out_channels\n",
    "        k      = conv.kernel_size  # assuming square kernels\n",
    "        w, b = init_conv(in_ch, out_ch, k, scale=scale)\n",
    "        load_needle_conv(conv, w, b, device=device, dtype=dtype)\n",
    "\n",
    "    for lin in linears:\n",
    "        in_dim  = lin.in_features\n",
    "        out_dim = lin.out_features\n",
    "        w, b = init_linear(in_dim, out_dim, scale=scale)\n",
    "        load_needle_linear(lin, w, b, device=device, dtype=dtype)\n",
    "\n",
    "    for bn in bns:\n",
    "        dim = bn.dim\n",
    "        gamma, beta, running_mean, running_var = init_bn(dim)\n",
    "        load_needle_bn(bn, gamma, beta, running_mean, running_var, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d42e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch CPU \n",
    "\n",
    "def make_torch_cpu_model_and_data(batch_size=64):\n",
    "    model = TorchResNet9(device=device_torch_cpu)\n",
    "    sync_torch_resnet9_weights(model, device=device_torch_cpu)\n",
    "    x = torch.from_numpy(\n",
    "        rng.standard_normal((batch_size, 3, 64, 64), dtype=np.float32)\n",
    "    ).to(device_torch_cpu, dtype=torch.float32)\n",
    "    y = torch.from_numpy(\n",
    "        rng.integers(0, 10, size=(batch_size,), dtype=np.int64)\n",
    "    ).to(device_torch_cpu, dtype=torch.int64)\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_torch_cpu_resnet9_inference_step(model, x):\n",
    "    x = x.to(device_torch_cpu)\n",
    "\n",
    "    def fn():\n",
    "        _ = model(x)\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# PyTorch MPS\n",
    "\n",
    "def make_torch_mps_model_and_data(batch_size=64):\n",
    "    model = TorchResNet9(device=device_torch_mps)\n",
    "    sync_torch_resnet9_weights(model, device=device_torch_mps)\n",
    "    x = torch.from_numpy(\n",
    "        rng.standard_normal((batch_size, 3, 64, 64), dtype=np.float32)\n",
    "    ).to(device_torch_mps, dtype=torch.float32)\n",
    "    y = torch.from_numpy(\n",
    "        rng.integers(0, 10, size=(batch_size,), dtype=np.int64)\n",
    "    ).to(device_torch_mps, dtype=torch.int64)\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_torch_mps_resnet9_inference_step(model, x):\n",
    "    x = x.to(device_torch_mps)\n",
    "\n",
    "    def fn():\n",
    "        _ = model(x)\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=torch_mps_synchronize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needle CPU\n",
    "\n",
    "def make_needle_cpu_model_and_data(batch_size=64):\n",
    "    model = NeedleResNet9(device=device_needle_cpu)\n",
    "    sync_needle_resnet9_weights(model, device=device_needle_cpu)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, 3, 64, 64), dtype=np.float32),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, 10, size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_cpu,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_cpu_resnet9_inference_step(model, x):\n",
    "    assert x.device == device_needle_cpu, x.device\n",
    "\n",
    "    def fn():\n",
    "        _ = model(x)\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=None)\n",
    "\n",
    "\n",
    "# Needle MSL\n",
    "\n",
    "def make_needle_msl_model_and_data(batch_size=64):\n",
    "    model = NeedleResNet9(device=device_needle_msl)\n",
    "    sync_needle_resnet9_weights(model, device=device_needle_msl)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, 3, 64, 64), dtype=np.float32),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, 10, size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_msl,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_msl_resnet9_inference_step(model, x):\n",
    "    assert x.device == device_needle_msl, x.device\n",
    "\n",
    "    def fn():\n",
    "        _ = model(x)\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_msl_synchronize)\n",
    "\n",
    "\n",
    "# Needle MPS\n",
    "\n",
    "def make_needle_mps_model_and_data(batch_size=64):\n",
    "    model = NeedleResNet9(device=device_needle_mps)\n",
    "    sync_needle_resnet9_weights(model, device=device_needle_mps)\n",
    "    x = needle.Tensor(\n",
    "        rng.standard_normal((batch_size, 3, 64, 64), dtype=np.float32),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    y = needle.Tensor(\n",
    "        rng.integers(0, 10, size=(batch_size,), dtype=np.int64),\n",
    "        device=device_needle_mps,\n",
    "        dtype=\"float32\",\n",
    "        requires_grad=False\n",
    "    )\n",
    "    return model, x, y\n",
    "\n",
    "def benchmark_needle_mps_resnet9_inference_step(model, x):\n",
    "    assert x.device == device_needle_mps, x.device\n",
    "\n",
    "    def fn():\n",
    "        _ = model(x)\n",
    "    return benchmark_fn(fn, warmup=10, iters=50, sync_fn=needle_mps_synchronize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1064446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_resnet9_benchmarks(batch_sizes):\n",
    "    results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        label = f\"resnet9_batch{batch_size}\"\n",
    "\n",
    "        print(f\"\\n=== ResNet9: {label} ===\")\n",
    "\n",
    "        # PyTorch CPU\n",
    "        model_torch_cpu, x_torch_cpu, y_torch_cpu = make_torch_cpu_model_and_data(\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        mean_ms, std_ms = benchmark_torch_cpu_resnet9_inference_step(\n",
    "            model_torch_cpu, x_torch_cpu\n",
    "        )\n",
    "        print(f\"  PyTorch CPU: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"pytorch\",\n",
    "            device=\"cpu\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # PyTorch MPS\n",
    "        if device_torch_mps is not None:\n",
    "            model_torch_mps, x_torch_mps, y_torch_mps = make_torch_mps_model_and_data(\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            mean_ms, std_ms = benchmark_torch_mps_resnet9_inference_step(\n",
    "                model_torch_mps, x_torch_mps\n",
    "            )\n",
    "            print(f\"  PyTorch MPS: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "            results.append(dict(\n",
    "                label=label,\n",
    "                framework=\"pytorch\",\n",
    "                device=\"mps\",\n",
    "                mean_ms=mean_ms,\n",
    "                std_ms=std_ms,\n",
    "            ))\n",
    "        \n",
    "        # Needle CPU\n",
    "        model_needle_cpu, x_needle_cpu, y_needle_cpu = make_needle_cpu_model_and_data(\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        mean_ms, std_ms = benchmark_needle_cpu_resnet9_inference_step(\n",
    "            model_needle_cpu, x_needle_cpu\n",
    "        )\n",
    "        print(f\"  Needle CPU: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"cpu\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # Needle MSL\n",
    "        model_needle_msl, x_needle_msl, y_needle_msl = make_needle_msl_model_and_data(\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        mean_ms, std_ms = benchmark_needle_msl_resnet9_inference_step(\n",
    "            model_needle_msl, x_needle_msl\n",
    "        )\n",
    "        print(f\"  Needle MSL: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"msl\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "        # Needle MPS\n",
    "        model_needle_mps, x_needle_mps, y_needle_mps = make_needle_mps_model_and_data(\n",
    "            batch_size\n",
    "        )\n",
    "        mean_ms, std_ms = benchmark_needle_mps_resnet9_inference_step(\n",
    "            model_needle_mps, x_needle_mps\n",
    "        )\n",
    "        print(f\"  Needle MPS: {mean_ms:.3f} ± {std_ms:.3f} ms\")\n",
    "        results.append(dict(\n",
    "            label=label,\n",
    "            framework=\"needle\",\n",
    "            device=\"mps\",\n",
    "            mean_ms=mean_ms,\n",
    "            std_ms=std_ms,\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resnet9_mean_ms_grouped(df, only_needle=False, show_needle_cpu=True):\n",
    "    labels = df[\"label\"].unique()\n",
    "    \n",
    "    groups = df[[\"framework\", \"device\"]].drop_duplicates()\n",
    "    groups = list(groups.itertuples(index=False, name=None))\n",
    "    if only_needle:\n",
    "        groups = [g for g in groups if g[0] == \"needle\"]\n",
    "    if not show_needle_cpu:\n",
    "        groups = [g for g in groups if not (g[0] == \"needle\" and g[1] == \"cpu\")]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.8 / max(1, len(groups))\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    for i, (framework, device) in enumerate(groups):\n",
    "        sub = df[(df[\"framework\"] == framework) & (df[\"device\"] == device)].set_index(\"label\")\n",
    "        sub = sub.loc[labels]  # keep original order\n",
    "        backend_label = f\"{framework.capitalize()} {device.upper()}\"\n",
    "        color = COLOR_MAP[(framework, device)]\n",
    "        plt.bar(x + i * width, sub[\"mean_ms\"], width, label=backend_label, color=color)\n",
    "    plt.xticks(x + width * (len(groups)-1)/2, labels, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Mean time per inference step (ms)\")\n",
    "    plt.title(\"ResNet9 Inference Performance by Backend\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be34d74",
   "metadata": {},
   "source": [
    "### Run ResNet9 Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0240551",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET9_BATCH_SIZES = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resnet9 = run_all_resnet9_benchmarks(RESNET9_BATCH_SIZES)\n",
    "df_resnet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resnet9_mean_ms_grouped(df_resnet9, only_needle=False, show_needle_cpu=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
